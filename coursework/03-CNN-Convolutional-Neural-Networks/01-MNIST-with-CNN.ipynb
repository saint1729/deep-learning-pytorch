{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"../Pierian-Data-Logo.PNG\">\n",
    "<br>\n",
    "<strong><center>Copyright 2019. Created by Jose Marcial Portilla.</center></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Code Along with CNN\n",
    "Now that we've seen the results of an artificial neural network model on the <a href='https://en.wikipedia.org/wiki/MNIST_database'>MNIST dataset</a>, let's work the same data with a <a href='https://en.wikipedia.org/wiki/Convolutional_neural_network'>Convolutional Neural Network</a> (CNN).\n",
    "Make sure to watch the theory lectures! You'll want to be comfortable with:\n",
    "* convolutional layers\n",
    "* filters/kernels\n",
    "* pooling\n",
    "* depth, stride and zero-padding\n",
    "\n",
    "Note that in this exercise there is no need to flatten the MNIST data, as a CNN expects 2-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST dataset\n",
    "PyTorch makes the MNIST train and test datasets available through <a href='https://pytorch.org/docs/stable/torchvision/index.html'><tt><strong>torchvision</strong></tt></a>. The first time they're called, the datasets will be downloaded onto your computer to the path specified. From that point, torchvision will always look for a local copy before attempting another download.\n",
    "\n",
    "Refer to the previous section for explanations of transformations, batch sizes and <a href='https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader'><tt><strong>DataLoader</strong></tt></a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = datasets.MNIST(root='../Data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='../Data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../Data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ../Data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create loaders\n",
    "When working with images, we want relatively small batches; a batch size of 4 is not uncommon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a convolutional model\n",
    "In the previous section we used only fully connected layers, with an input layer of 784 (our flattened 28x28 images), hidden layers of 120 and 84 neurons, and an output size representing 10 possible digits.\n",
    "\n",
    "This time we'll employ two convolutional layers and two pooling layers before feeding data through fully connected hidden layers to our output. The model follows CONV/RELU/POOL/CONV/RELU/POOL/FC/RELU/FC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>Let's walk through the steps we're about to take.</strong><br>\n",
    "\n",
    "1. Extend the base Module class:\n",
    "   \n",
    "<tt><font color=black>class ConvolutionalNetwork(nn.Module):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;def \\_\\_init\\_\\_(self):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super().\\_\\_init\\_\\_()</font></tt><br>\n",
    "\n",
    "2. Set up the convolutional layers with <a href='https://pytorch.org/docs/stable/nn.html#conv2d'><tt><strong>torch.nn.Conv2d()</strong></tt></a><br><br>The first layer has one input channel (the grayscale color channel). We'll assign 6 output channels for feature extraction. We'll set our kernel size to 3 to make a 3x3 filter, and set the step size to 1.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.conv1 = nn.Conv2d(1, 6, 3, 1)</font></tt><br>\n",
    "The second layer will take our 6 input channels and deliver 16 output channels.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.conv2 = nn.Conv2d(6, 16, 3, 1)</font></tt><br><br>\n",
    "\n",
    "3. Set up the fully connected layers with <a href='https://pytorch.org/docs/stable/nn.html#linear'><tt><strong>torch.nn.Linear()</strong></tt></a>.<br><br>The input size of (5x5x16) is determined by the effect of our kernels on the input image size. A 3x3 filter applied to a 28x28 image leaves a 1-pixel edge on all four sides. In one layer the size changes from 28x28 to 26x26. We could address this with zero-padding, but since an MNIST image is mostly black at the edges, we should be safe ignoring these pixels. We'll apply the kernel twice, and apply pooling layers twice, so our resulting output will be \n",
    "$\\;(((28-2)/2)-2)/2 = 5.5\\;$ which rounds down to 5 pixels per side.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.fc1 = nn.Linear(5\\*5\\*16, 120)</font></tt><br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.fc2 = nn.Linear(120, 84)</font></tt><br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.fc3 = nn.Linear(84, 10)</font></tt><br>\n",
    "See below for a more detailed look at this step.<br><br>\n",
    "\n",
    "4. Define the forward method.<br><br>Activations can be applied to the convolutions in one line using <a href='https://pytorch.org/docs/stable/nn.html#id27'><tt><strong>F.relu()</strong></tt></a> and pooling is done using <a href='https://pytorch.org/docs/stable/nn.html#maxpool2d'><tt><strong>F.max_pool2d()</strong></tt></a><br>\n",
    "<tt><font color=black>def forward(self, X):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.relu(self.conv1(X))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.max_pool2d(X, 2, 2)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.relu(self.conv2(X))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.max_pool2d(X, 2, 2)<br>\n",
    "</font></tt>Flatten the data for the fully connected layers:<br><tt><font color=black>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = X.view(-1, 5\\*5\\*16)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = F.relu(self.fc1(X))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;X = self.fc2(X)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;return F.log_softmax(X, dim=1)</font></tt>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><strong>Breaking down the convolutional layers</strong> (this code is for illustration purposes only.)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define layers\n",
    "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "conv2 = nn.Conv2d(6, 16, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the first MNIST record\n",
    "for i, (X_train, y_train) in enumerate(train_data):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Create a rank-4 tensor to be passed into the model\n",
    "# (train_loader will have done this already)\n",
    "x = X_train.view(1,1,28,28)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "# Perform the first convolution/activation\n",
    "x = F.relu(conv1(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "# Run the first pooling layer\n",
    "x = F.max_pool2d(x, 2, 2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 11, 11])\n"
     ]
    }
   ],
   "source": [
    "# Perform the second convolution/activation\n",
    "x = F.relu(conv2(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# Run the second pooling layer\n",
    "x = F.max_pool2d(x, 2, 2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 400])\n"
     ]
    }
   ],
   "source": [
    "# Flatten the data\n",
    "x = x.view(-1, 5*5*16)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><strong>This is how the convolution output is passed into the fully connected layers.</strong></div>\n",
    "\n",
    "Now let's run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 5*5*16)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ConvolutionalNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including the bias terms for each layer, the total number of parameters being trained is:<br>\n",
    "\n",
    "$\\quad\\begin{split}(1\\times6\\times3\\times3)+6+(6\\times16\\times3\\times3)+16+(400\\times120)+120+(120\\times84)+84+(84\\times10)+10 &=\\\\\n",
    "54+6+864+16+48000+120+10080+84+840+10 &= 60,074\\end{split}$<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    54\n",
      "     6\n",
      "   864\n",
      "    16\n",
      " 48000\n",
      "   120\n",
      " 10080\n",
      "    84\n",
      "   840\n",
      "    10\n",
      "______\n",
      " 60074\n"
     ]
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "This time we'll feed the data directly into the model without flattening it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  batch:  600 [  6000/60000]  loss: 0.48169690  accuracy:  78.400%\n",
      "epoch:  0  batch: 1200 [ 12000/60000]  loss: 0.10990709  accuracy:  85.400%\n",
      "epoch:  0  batch: 1800 [ 18000/60000]  loss: 0.01810435  accuracy:  88.528%\n",
      "epoch:  0  batch: 2400 [ 24000/60000]  loss: 0.10995674  accuracy:  90.267%\n",
      "epoch:  0  batch: 3000 [ 30000/60000]  loss: 0.00261936  accuracy:  91.470%\n",
      "epoch:  0  batch: 3600 [ 36000/60000]  loss: 0.05913165  accuracy:  92.392%\n",
      "epoch:  0  batch: 4200 [ 42000/60000]  loss: 0.11463086  accuracy:  93.002%\n",
      "epoch:  0  batch: 4800 [ 48000/60000]  loss: 0.00280169  accuracy:  93.475%\n",
      "epoch:  0  batch: 5400 [ 54000/60000]  loss: 0.00556864  accuracy:  93.896%\n",
      "epoch:  0  batch: 6000 [ 60000/60000]  loss: 0.05991982  accuracy:  94.255%\n",
      "epoch:  1  batch:  600 [  6000/60000]  loss: 0.05310615  accuracy:  97.717%\n",
      "epoch:  1  batch: 1200 [ 12000/60000]  loss: 0.00405396  accuracy:  97.858%\n",
      "epoch:  1  batch: 1800 [ 18000/60000]  loss: 0.03800049  accuracy:  97.956%\n",
      "epoch:  1  batch: 2400 [ 24000/60000]  loss: 0.01596840  accuracy:  97.925%\n",
      "epoch:  1  batch: 3000 [ 30000/60000]  loss: 0.00006104  accuracy:  97.917%\n",
      "epoch:  1  batch: 3600 [ 36000/60000]  loss: 0.12193976  accuracy:  97.869%\n",
      "epoch:  1  batch: 4200 [ 42000/60000]  loss: 0.01460361  accuracy:  97.888%\n",
      "epoch:  1  batch: 4800 [ 48000/60000]  loss: 0.18480448  accuracy:  97.881%\n",
      "epoch:  1  batch: 5400 [ 54000/60000]  loss: 0.07728766  accuracy:  97.872%\n",
      "epoch:  1  batch: 6000 [ 60000/60000]  loss: 0.34217340  accuracy:  97.907%\n",
      "epoch:  2  batch:  600 [  6000/60000]  loss: 0.00537706  accuracy:  98.367%\n",
      "epoch:  2  batch: 1200 [ 12000/60000]  loss: 0.00666555  accuracy:  98.342%\n",
      "epoch:  2  batch: 1800 [ 18000/60000]  loss: 0.01125053  accuracy:  98.539%\n",
      "epoch:  2  batch: 2400 [ 24000/60000]  loss: 0.00557309  accuracy:  98.571%\n",
      "epoch:  2  batch: 3000 [ 30000/60000]  loss: 0.00227616  accuracy:  98.520%\n",
      "epoch:  2  batch: 3600 [ 36000/60000]  loss: 0.03163021  accuracy:  98.553%\n",
      "epoch:  2  batch: 4200 [ 42000/60000]  loss: 0.00236438  accuracy:  98.538%\n",
      "epoch:  2  batch: 4800 [ 48000/60000]  loss: 0.00051380  accuracy:  98.531%\n",
      "epoch:  2  batch: 5400 [ 54000/60000]  loss: 0.00362411  accuracy:  98.539%\n",
      "epoch:  2  batch: 6000 [ 60000/60000]  loss: 0.00020174  accuracy:  98.568%\n",
      "epoch:  3  batch:  600 [  6000/60000]  loss: 0.00218589  accuracy:  98.817%\n",
      "epoch:  3  batch: 1200 [ 12000/60000]  loss: 0.01807746  accuracy:  98.833%\n",
      "epoch:  3  batch: 1800 [ 18000/60000]  loss: 0.00020335  accuracy:  98.789%\n",
      "epoch:  3  batch: 2400 [ 24000/60000]  loss: 0.00067853  accuracy:  98.804%\n",
      "epoch:  3  batch: 3000 [ 30000/60000]  loss: 0.00022620  accuracy:  98.840%\n",
      "epoch:  3  batch: 3600 [ 36000/60000]  loss: 0.26363233  accuracy:  98.833%\n",
      "epoch:  3  batch: 4200 [ 42000/60000]  loss: 0.00038978  accuracy:  98.850%\n",
      "epoch:  3  batch: 4800 [ 48000/60000]  loss: 0.01715825  accuracy:  98.800%\n",
      "epoch:  3  batch: 5400 [ 54000/60000]  loss: 0.00592389  accuracy:  98.826%\n",
      "epoch:  3  batch: 6000 [ 60000/60000]  loss: 0.00039336  accuracy:  98.805%\n",
      "epoch:  4  batch:  600 [  6000/60000]  loss: 0.00052552  accuracy:  99.183%\n",
      "epoch:  4  batch: 1200 [ 12000/60000]  loss: 0.22423601  accuracy:  99.058%\n",
      "epoch:  4  batch: 1800 [ 18000/60000]  loss: 0.00000136  accuracy:  99.089%\n",
      "epoch:  4  batch: 2400 [ 24000/60000]  loss: 0.00005473  accuracy:  99.096%\n",
      "epoch:  4  batch: 3000 [ 30000/60000]  loss: 0.02662337  accuracy:  99.007%\n",
      "epoch:  4  batch: 3600 [ 36000/60000]  loss: 0.08865079  accuracy:  99.042%\n",
      "epoch:  4  batch: 4200 [ 42000/60000]  loss: 0.00068114  accuracy:  99.050%\n",
      "epoch:  4  batch: 4800 [ 48000/60000]  loss: 0.01170583  accuracy:  99.046%\n",
      "epoch:  4  batch: 5400 [ 54000/60000]  loss: 0.00004394  accuracy:  99.019%\n",
      "epoch:  4  batch: 6000 [ 60000/60000]  loss: 0.00065719  accuracy:  99.017%\n",
      "\n",
      "Duration: 112 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        \n",
    "        # Apply the model\n",
    "        y_pred = model(X_train)  # we don't flatten X-train here\n",
    "        loss = criterion(y_pred, y_train)\n",
    " \n",
    "        # Tally the number of correct predictions\n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print interim results\n",
    "        if b%600 == 0:\n",
    "            print(f'epoch: {i:2}  batch: {b:4} [{10*b:6}/60000]  loss: {loss.item():10.8f}  \\\n",
    "accuracy: {trn_corr.item()*100/(10*b):7.3f}%')\n",
    "        \n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "        \n",
    "    # Run the testing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "\n",
    "            # Apply the model\n",
    "            y_val = model(X_test)\n",
    "\n",
    "            # Tally the number of correct predictions\n",
    "            predicted = torch.max(y_val.data, 1)[1] \n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "            \n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "        \n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss and accuracy comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   1626\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1627\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1628\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'values'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e235ce20c3cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss at the end of each epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2759\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2760\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2761\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m   2763\u001b[0m         is not None else {}), **kwargs)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     '''\n\u001b[1;32m   1325\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1327\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36matleast_1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asanyarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(test_losses, label='validation loss')\n",
    "plt.title('Loss at the end of each epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0067),\n",
       " tensor(0.0011),\n",
       " tensor(2.5534e-05),\n",
       " tensor(9.3650e-05),\n",
       " tensor(0.0005)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there may be some overfitting of the training data, there is far less than we saw with the ANN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([t/600 for t in train_correct], label='training accuracy')\n",
    "plt.plot([t/100 for t in test_correct], label='validation accuracy')\n",
    "plt.title('Accuracy at the end of each epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data all at once, not in batches\n",
    "test_load_all = DataLoader(test_data, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 9848/10000 =  98.480%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for X_test, y_test in test_load_all:\n",
    "        y_val = model(X_test)  # we don't flatten the data this time\n",
    "        predicted = torch.max(y_val,1)[1]\n",
    "        correct += (predicted == y_test).sum()\n",
    "print(f'Test accuracy: {correct.item()}/{len(test_data)} = {correct.item()*100/(len(test_data)):7.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that our [784,120,84,10] ANN returned an accuracy of 97.25% after 10 epochs. And it used 105,214 parameters to our current 60,074."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1    2    3    4    5    6    7    8    9]]\n",
      "\n",
      "[[ 977    0    3    2    2    2    4    1   10    2]\n",
      " [   0 1132    5    1    1    0    3    7    1    2]\n",
      " [   0    0 1015    1    0    0    0    4    3    0]\n",
      " [   0    2    0 1001    0   11    0    1    3    4]\n",
      " [   0    0    1    0  966    0    1    0    2    2]\n",
      " [   0    0    0    1    0  863    2    0    0    2]\n",
      " [   1    0    0    0    3    4  948    0    0    0]\n",
      " [   1    0    5    0    0    1    0 1005    1    2]\n",
      " [   1    1    3    4    1    4    0    2  948    2]\n",
      " [   0    0    0    0    9    7    0    8    6  993]]\n"
     ]
    }
   ],
   "source": [
    "# print a row of values for reference\n",
    "np.set_printoptions(formatter=dict(int=lambda x: f'{x:4}'))\n",
    "print(np.arange(10).reshape(1,10))\n",
    "print()\n",
    "\n",
    "# print the confusion matrix\n",
    "print(confusion_matrix(predicted.view(-1), y_test.view(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the misses\n",
    "We can track the index positions of \"missed\" predictions, and extract the corresponding image and label. We'll do this in batches to save screen space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misses = np.array([])\n",
    "for i in range(len(predicted.view(-1))):\n",
    "    if predicted[i] != y_test[i]:\n",
    "        misses = np.append(misses,i).astype('int64')\n",
    "        \n",
    "# Display the number of misses\n",
    "len(misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  18,  111,  175,  184,  247,  321,  340,  412,  445,  460],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 index positions\n",
    "misses[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an iterator to feed batched rows\n",
    "r = 12   # row size\n",
    "row = iter(np.array_split(misses,len(misses)//r+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is set up, run and re-run the cell below to view all of the missed predictions.<br>\n",
    "Use <kbd>Ctrl+Enter</kbd> to remain on the cell between runs. You'll see a <tt>StopIteration</tt> once all the misses have been seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: [  18  111  175  184  247  321  340  412  445  460  495  582]\n",
      "Label: [   3    7    7    8    4    2    5    5    6    5    8    8]\n",
      "Guess: [   8    1    1    3    6    7    3    3    0    9    0    2]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAABUCAYAAACm27J5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXl4VNXZwH8HiAgkLBIMmxKIQbBoZakoKEqhVEENIlaRRdQAgtSwVJaAAhUUFSluqEFQQCwuwSK2SgGh2ErZBYSAAiIEWeSrbC4syfn+uHMOk2QmTDKZeyfw/p7nPjNz752Zd945c+ecd1VaawRBEARBEITiUcZrAQRBEARBEEozMpkSBEEQBEEIA5lMCYIgCIIghIFMpgRBEARBEMJAJlOCIAiCIAhhIJMpQRAEQRCEMAhrMqWUulkptU0ptV0pNaKkhBIEQRAEQSgtqOLWmVJKlQW+An4HZAOrgW5a6y0lJ54gCIIgCEJ0E45l6hpgu9Z6p9b6JDAXSCkZsQRBEARBEEoH5cJ4bh1gj9/jbKBlYU9QSkm5dUEQBEEQSguHtNY1znZSOJMpFWBfgcmSUqov0DeM9xEEQRAEQfCCb0M5KZzJVDZwid/jusB3+U/SWmcAGSCWKUEQBEEQzj3CiZlaDSQrpeorpS4A7gE+LBmxBEEQBEEQSgfFtkxprU8rpQYCC4GywAyt9eYSk0wQBEEQBKEUUOzSCMV6M3HzCYIgCIJQelirtW5xtpPCiZkSBMEjKlasCMDcuXPZuXMnAIMGDfJSJEEQhPMWaScjCIIgCIIQBuLmE4RSSMOGDQHYunUrP//8MwB169blhx9+8FKsc5qGDRvy2muvAfD2228zbdo0jyUShJKlefPmLFq0CIDDhw9z8803A/DVV195KZbXlH43X2xsLACXXHIJ/fv3t/tnzJgBwBdffOGJXELpIzY2lq5duxbY37p1ax544AEA/va3vwEwbdo0PvnkE1flC4eDBw8CcPLkSY8lOTcxE9e///3v1K9fH4DExESZTAnnBBUrVrSLhE6dOlG5cmUAKleuzHvvvQfAr3/9a8/kK4zc3FwA5s2bh1JO6cstW5yOdo899pirsoibTxAEQRAEIQyi1jIVGxvLo48+CsDo0aPzHHvooYcAeOeddwBIS0vjf//7n7sCCqUCY92cPHkyv/3tbwHHNfZ///d/9hxjhbrxxhvtbVpaGgBz5sxxU9xi8fHHHwPw448/eizJuUdaWpodC5deeqnd/+23IRVFFkLgkUceAeCFF17wWJLziyuvvBJwPD1NmzYFQCmFf+jPsmXLvBAtZIysnTt3tpaplBSnRfD69euZN2+ea7JEbczUhAkTGDFiREjn7t+/n/vvvx+Af/7zn8UTziUSExOt26BHjx7WbbBz504aNGgAnPkDf+ONNzhx4oQ3ggahcuXKPPHEEwD84Q9/4OjRowDEx8czf/58AAYMGMAvv/zimYz+XH311QC0adPmrBfrMWPGAHkn7zExMZETLgz+8pe/ANC/f3+uuuoqIHriGqpWrUpycjIA9957r92flpZGoOvN/v37AWjVqlXUTFLKlXPWmS+//DKpqamAc+E2Ou7QoQPZ2dmeyFa1alU++OADwBnXhu+//54JEyYA8OKLL5KYmAg4cpv7xl2T/3swf0Raaz780Km9HMnvolKlSkycOBHAXgNvvfXWiL2fcIbatWsD8Oc//xmA3r1722P5J1M//fQT4FxnonFh2bfvmU5148ePB6B69eoArFu3jt/85jcl8TYhxUyJm08QBEEQBCEMotYy1adPH1599VXAWS29/PLLAGzevNlaC8zMumrVqjb49umnn+aZZ54BzsyqowGzGvj888+55BKnpWH+VYDBrBIff/xxO9v2mt/97ncADBkyhOPHjwOOpeG775x2jC1atGDVqlWA872MHTvWEznDoWrVqgBs2LDBfl9XXnklW7du9VKsAlx66aU2+UJrbVdiXtO9e3cA0tPTufzyywscV0qxYcMGAC644AIAGjVqZI+3bt2alStXuiDp2Xn44YcBeP755/NYbVasWAHADTfc4LpMNWo4jevffPNNfv/73xd67s6dO6lQoYJ9bOqSmTFemGWqU6dOACxcuLBkBA9AkyZN7Fho2bIlAGvWrInY+7lFTEwMcXFxAKSmptrvqW3btoCj5z59+gAwc+ZMTp065bqMxkI/YMCAAseC/SeB81sA5/o4a9asyAlYTMx8wViS169fL5YpQRAEQRCE0kLUBqB37tzZ3n/vvfdsEKg/GzduBJy0yIsuughw0iGTkpIAeOCBBzyZ+QfC1P+ZPXs26enpAJw4cYKMjAwAdu/ebS1qhoceesimrH7//fcuSluQm266CXDq68yePbvA8W3bttk02rp167opWolhPmOVKlXsvmix+vjTvn17a2EYOXKkx9I43HvvvXZlWKFCBTve582bZy0Qy5cvt3E4JiZpz549XHjhhfY1vLZMGYukWd0qpShTxllz5ubm2qQYL2jRwlkcn80qBZCUlBTUwhCI7du3A45Vee3atcUTsAhMmTKFL7/8EsDWSStt9OzZE8hrpUxISAgY+2W+C621vabv3r3b9Rjf5s2b06NHD+CMNdKfMmXK2HID+RkyZAjgJH5Fo2XKYD7XZ5995ur7Ru1kqmPHjvZLDebqMspKSUnhqaeeAuD666+3Qa9KKRtcd/r06QhLXDjmgjFp0iTr5vvoo494//33AahZs2aBydSFF15o/2i8ZtSoUYUe//nnn219kmgJIi4qJlg9Li6Of//73wD85z//8VKkPFx88cUADBs2jAMHDgCOy8dLjPvowQcftH/C48ePt3oL9kdpXFD+f/jvvvtuJEUNiXr16gFnMp201vY6tGDBAtatW+eZbKZ+zvjx4wtkOBcHs0CbMGECL730UtivFwomXKBcuXIh1y5KSkqyi4e1a9dal1nr1q3znGcm7QsWLCgpcQtgFlfPPvusnZSULVs25Od/++23dhJp5HWTgQMH2uu0/2/PhA2kpKTY72XQoEE2AxrO1HTq1KmTTfh64403XJE7FO644w7gzOcySRpuIW4+QRAEQRCEMIhay9TixYvtrPhs9XM+//xzhg0bBjhViqtVqwZAt27dbJpvNKx6AY4cOZInFdVQq1atAmbXQGbYaCU1NZU6deoATskELzHWvFGjRnH99dcDeVdhjz76KNu2bbOPTRC0Mdvn5uYyffp0t8QNmVtuuQVwKnIbi+aBAwesladcuXIcO3bMVZlMkke7du2K9LyhQ4cCjoXKuJiiIdDf6M/UIfN381533XW25MPmzZtdl81YfMeOHcumTZsAJ1DevzzC2XjxxRcB75piGxdlMFeScbOabgTglGMpX748AHv37iU+Ph7AfheGQ4cOAWf0dM0115Sg5A6m+0ZhZRyMxc/fivncc88Bzhjfu3dvicsVKr169Srg/l21ahV33nknAPv27bPy/fDDD3ksU4affvrJWsajCWOJMgH+4ubzkZWVFfCLTE1NtW4843v2569//WueLIX8P7hopV27dnaQm0lU+fLl82TkRDO1a9fmyJEjAK7/oeenZs2aAJw6dYqlS5cCzkXEuHD++9//2km2Uorbbrstz/N37drliQm+MCpVqmQne4B1CZcrV465c+cCTrxGx44dAaK2iK3Jrhk+fLjd98orrwDkKaTqFcYFY/7MH3zwQXusevXq9tpisv28IjMzE3B+d0WZTPXq1Qtw3LP+NXrcoHbt2taFlJqaamPAdu/eDThtkcxkpXLlyvY6eNlll9nXmDlzpnWrmdhTg5lkmazikqZ169a0b9++wP5ffvnF6vLLL7+0tfe++eabiMhR0kyfPt264+Pi4qxL1X/s+/Ppp5/yj3/8wzX5CsNkuI4cOdK6+bKysjyRRdx8giAIgiAIYRC1lin/miNXXXWVdd289NJLts6Uaf9RGCYrZ9u2bbYbtrGgRBONGzcusG/jxo1RU9W6NLFr1y7gTB0ycFbypk5K1apVuf3224HA2St333131FmmBg8ebC21S5cutb+PDh065LGsmeSGaLRMlSlThg4dOgBnAtCPHDlirYfRhEl6yb86N+MmIyPD0zFirDZFtS6ZTNXbbruNm2++GcC1pt6zZ8+2GbOvvfaabc9j6pMdPHjQ1rC766677GdMSEiwr7F8+XI7xrt27Wqrp8fExNi6WKZxeUkTFxeXJyHIXDe6du1qWzqVRiZNmmRbtB0/fvysNdSMVd8rjIfh+++/t0kAaWlp1roWyrwgImitXdsAHepWuXJl3aNHD92jRw8dGxurk5KSdFJSkj58+LDOyckp1nb8+HF9/Phx3a1bN12xYkVdsWLFkOWJ1Na+fXvdvn37PJ8rNzdX5+bm6qFDh3ouX6jbli1b9PTp0/X06dM9l+Vs26xZs/SpU6f0qVOndE5Ojr1vtnHjxnkuo9maNGmimzRponfv3m3HRffu3XV8fLyOj4/X27Zts/v37t2rExISdEJCgudyB9r69OmjT58+nWfr27ev53IVtj333HPa4H8t+fbbbz2VSymllVIF9Gm2nJycoPvNsaysLJ2VlRVxWVu2bKlbtmypjx49qtesWaPXrFmjmzdvrufMmaPnzJmjGzRooBs0aFDk142Li9OzZs3Ss2bN0jk5Ofr111/Xr7/+esQ+R0xMjN64caPeuHFjnrFw6NAhPWDAAD1gwADdpk0bXaZMGV2mTBnPx27+cWzGcmH/kYUdT0lJ0SkpKZ5/lgMHDugDBw7o7t272/unT5/W6enpOj09PRLvuSaU+Y24+QRBEARBEMIgat18R48e5a233rKPjfm3e/fuNlvMFOo0Qbdnw7gW3nrrLRtoaoLZvcjOgTPZLab2hz/RVOMoGKbJbv369Rk3bpzH0gQnMTGRHTt2FNg/a9YsKlWqBGAzWkaPHs3OnTsBJ+DVbWJiYqwLxgRnmywncLJWzLjxT7DIycmxxTDLly8fdU2y/TOgTNCxF/otCv5FLF977TV7DalZs6ZtyzFjxgxbp8ctTLLKkCFDbNNrfzZt2mSLqGZmZtrikKaWWm5urm24PnDgwIjWmerXrx/gJFGYZrlr16617r3ikpCQEPZrFIU6derYNkj+VKtWzWZJAraVlmkI7zWvvPIK3bp1A5zvvbBiroUdN43svaRLly426Dw9Pd3ez8rK4sknn/RSNLFMCYIgCIIghEPUNjoOBZMiaxpLgrNaMZ/p4MGDdv+4ceNsYKKp2gxOPStwUrXdXl3GxcXx0UcfAdh6SIBdaQ4bNixoPZZowbQVqFChAn/605+A6KqAbgIU+/fvb+vOLFmyxK5ili9fboNKTTPtXr162cBjN9smmODgDz74wAbqFpc9e/bY5AuTeOEVTZs2BZykEvPbfOSRRwCYOnWqZ3IVFf/vxf+ac+DAAWvxcbvtU5UqVZgyZQrglAaYN28e4FQBN3WXzDEjK5DH+jBo0KCIWaYef/xxW619xYoVth5ZOB0pjOVn+PDh1nKbnp5OTk4OQERbiJmA9/xB2sY7csstt3D48GHAqUtmGsF7ganiv2TJEuvF8W9kbErYDB8+3AZ1jxgxIqhl6tlnnwVgzJgxnDx5MqKy+9O4cWO6dOli5TP/3xMmTOCKK64AnPZzY8aMsftLmJAaHYcSNH4JsBTIAjYDab79FwGLgK99t9VKMgA92BYfH69btWqlW7VqVeTnmudt2LChQHDdxx9/7Hog3aBBgwIG+lWrVk1Xq1bN80C/ULaVK1fqlStX6scee8xzWQJtRqenTp3Sixcv1osXL9ZVqlQJeO6YMWP0mDFj9KlTp3RmZqbOzMx0Tc4qVaroadOm6WnTptmA8tzcXH3s2DF97NgxPWbMGD148GA9ePBgvWrVqjznBNq2b9+uhw8frocPH+6p/itVqqTnz5+v58+fr7XWetGiRXrRokWej4vibv369dP9+vUrENRdp04dXadOHc/lO9vmH4ButoEDB0bs/XJzc+17Ll26NOzXe/LJJ/Xq1av16tWr9dixY/V1112nr7vuOs/1arapU6fazzt69GjPZZk6dWqBsfrZZ5/pzz77TLdt21a3bds2z3NeeOEFfeLECX3ixImgyQsRCvIusNWrV0/Xq1dPZ2Zm2uvasmXL9K5du/SuXbt0o0aNdPPmzXXz5s31E088kSdBp3v37iUpS4kFoJ8GhmqtGwPXAg8rpa4ARgBLtNbJwBLfY0EQBEEQhPOKswaga633Aft8948ppbKAOkAKcJPvtJnAMmB4gJcoEUwtnSlTpthg3HvuuQcIPTDu888/BxyXmin136BBA8Axybpdd8UEPBsyMjIAp4y/ED7GLA2QnZ1t9R1KnTHT6DjSmJppkyZNClhx2JiuJ0+ebN2R/k1utdZs3LgRcMz5xm28bt06W4nZS3r37k2nTp0Apw1FNDVGLQ5G1+cSXbp0iZibz9+tFBcXZ7sT7N+/P+TXaNGiha2D1KtXL/bt2wc4LniTKBItvPTSSzZBys0QmvxcffXVBTo7GIxrPVB9t0ceeYSUlBQA2x4sP8Z9GGlMiEXr1q2t+3zIkCE2eeXQoUPW5ZeVlWXbyZjK+D///LN1e7tBkbL5lFKJQFNgJZDgm2ihtd6nlLq4xKXzw8Qo1K5d22ZUmJYKN9xwAytWrAj5tY4dO2az+MwEKy4uzra4cGsy5d/1/MiRI3mKTJYGkpOTbRai+ROPJvz7qmVkZASdRJl4ElOQEdxrbWKy8fJPpEwmqyk0Ck4xUXCyWM2F+pNPPrGTlWjCfC7/DJtJkybx9ttveyVSQPwL/P3rX/8q9Nw+ffowcuRIIG/fzDJlSk8ej5HVPxYzkkUO/ScUTZs2tdmb3bp1K7Sw7FVXXcVdd90FOLGjpn3J2LFj7fcUbRMpgC1btth2JqZHrBc0bNgwTwawYf369QVawcTFxdn4ysmTJweN0zVjx42edzVq1LBxacuXLw8aQ2p6g8KZXohdu3YFnJhpU8DZv09ipAh5MqWUigUygUFa66OhNuFVSvUF3G0CJQiCIAiC4BIhTaaUUjE4E6k5WmtjNzuglKrls0rVAg4Geq7WOgPI8L1Ose2eZkVbu3Ztnn76aSMXULyVoamP5D8pdMuE798s06zcFixYYM3XpYXrr7+eoUOHAs6KJ1owroTLLrvMjg1jgczPZZddZs3aJiNr//79AWtSRYJhw4YV2PfNN9/w2GOPAdgMJTjT1FNrzezZswG4//77XZCyaCilrAXH1PCC6LJemlX7/PnzWb58OQAXX1zQuH777bdby01CQoLNINZa2+zflJSUIrmtSgJz3TKhCeBkS54tm9BYHdxyQe3YscOO27i4OHvtmzt3rm0abdzx/g2NK1eubOt4NWvWzF4bo7FNUn5MVvDgwYPt+P/xxx9dlcEv6SsPycnJtv6Vue6VLVvWXjMLqzNVt25doGgu2uJyxx13WDmM+66o9OzZ02b7RYVlSjm/2ulAltZ6st+hD4H7gIm+W1cqemVkZNgLSNu2bQHHt2pMvxMnTgzazy4tLQ1w+vUlJSUBeSdTblCpUqU8Bd4MkyZNclWOcDATlFtvvTUqe1L98ssvgOPONX8e/i4/49YDp8+UcUmZC3XPnj1dKZhavXp1O4YBm2587733BiwvYWIYTpw4wTvvvAMQlaUz7rzzTnr16mUfv/nmmwCsXr3aI4kKYiZFsbGx1k0arPivuUZorfOkky9YsADAk0WQiSHyv5b07t07T6FjQ506dejZs2fQ1zLFPSNBcnIyM2bMAJzCy9deey0A7dq1Y9u2bQXONyUTnn/+eZYsWQJ4V1C5uBjXU4sWLYiNjQXcn0wFIzY21k5iQ8EU/h03bhx79+6NlFgFOHTokA216Nu3L3v27AEIKQbKlFHIzMy018dAv4uSJhTLVGugJ7BJKWUKMaXjTKLeVUo9COwG7oqMiIIgCIIgCNFLKNl8/waCmW/alaw4Z+fo0aN07twZwHZtr1WrFvfddx/gWBWCrdZNq41ArF692pUA8Li4ONvGobRiikt26dLFulyjCVM0zxQoBMeiabJQ/APNL7/8cjtezCr/008/dUXOmJiYPF3ojYVk5cqVAc9/5plnAMcSG01u1fzkH9+FFdG7++67rZXNTYz79NixYwFbOfmTnZ0NOK5skxAQKBPKTS6//PIC+0aNGhVwBZ6RkWHbDwVi69atJSpbfiZOnAg4AeOXXnop4FiEExISCpxrsldLUzHXaGTFihV8/fXXQN6WU2cjOzs7z/+nyTA31x63mDdvnh0rqampNnGhUaNGQdvGjBo1CnAKe4JjtY9AAc+gRG1vvsIwffqMq+6+++6zZRKuvPJKatWqddbXMDE0CxcuBGDatGmuZXAZt4HbLsaSokmTJoATY7Zp0yaPpQmOvxuhSpUqeUoKGPbv30/v3r0BWLVqlVui2fcO9IcSDONOivbYuhYtzhQLHj9+vE1lLl++vDXBm+/CVEJ3G1OZunPnzrZCO8Af//hHAJYtWwY4Pe5MhfFoItA1pFq1alb+Nm3aWF3745/NN336dICI9uUD8oRdmAw8cw0RIkN2drZ1r59tQjFz5kx7HY+msW5kWbhwoQ0nMZO7/MyePZtGjRoB2Mr/Q4cOdbU0QunJ6RUEQRAEQYhCSnVvvkDUrFnT1qTq06ePXWG2aNHCrpDWrl1rV8smwM4tBg4caF0FSikbxHrnnXeG1a/KTYw1b9++fdYc77ZVJ1SM+1drbbNXGjZsaDOIduzY4Uqw+fnEvn37bAbX1KlTmTZtGgBz5syxPcDManny5MmlZtxHE2bVPnDgwIDH/Ytl+mOue++//77tcedfq0cIHZPlmZOTY4v8duzY0WbLHTp0yIYUuP0/c65hak5lZWXl6TnZuHFjwPn/eeqpp4Az1iv/88IkpN58YpkSBEEQBEEIg3POMhXt3Hjjjdaak5iYaON6mjVr5qVYReLgQaekWHx8vE11jlbLlOA+L7/8Mv369SuwXyllrVQmtV8oHmZFPm/ePBITE4EzrYkgr2Xq5MmTttSGiaMyVbqF4mNizVJTU20yVHJysk3QGT16tLWWCKWakCxTMpnyABMgn5aWZl2PphZLaWDRokWAE8Rr/jRNbSdBqFGjBosXLwbgV7/6lS1uOWHCBOsiFtdSyWGym/wLwCqlrLtp+/btrtTZOd+49dZbAWdc+wfUG1dqq1atoj5ZRAgJcfMJgiAIgiBEGrFMCYIgCEIxufvuu227s8zMTNsKKlCFd6FUIm4+QRAEQRCEMBA3nyAIgiAIQqSRyZQgCIIgCEIYyGRKEARBEAQhDGQyJQiCIAiCEAZuNzo+BPzouxVCJx7RWVERnRUd0VnREZ0VHdFZ0RGdFZ2S0lm9UE5yNZsPQCm1JpTIeOEMorOiIzorOqKzoiM6Kzqis6IjOis6butM3HyCIAiCIAhhIJMpQRAEQRCEMPBiMpXhwXuWdkRnRUd0VnREZ0VHdFZ0RGdFR3RWdFzVmesxU4IgCIIgCOcS4uYTBEEQBEEIA9cmU0qpm5VS25RS25VSI9x639KGUmqXUmqTUuoLpdQa376LlFKLlFJf+26reS2nlyilZiilDiqlvvTbF1BHyuEF37jbqJRq5p3k3hFEZ2OVUnt9Y+0LpVRHv2MjfTrbppT6vTdSe4tS6hKl1FKlVJZSarNSKs23X8ZaEArRmYy1ICilLlRKrVJKbfDpbJxvf32l1ErfOHtHKXWBb3953+PtvuOJXsrvBYXo7E2l1Dd+4+xq3/7I/za11hHfgLLADqABcAGwAbjCjfcubRuwC4jPt+8ZYITv/gjgaa/l9FhHbYBmwJdn0xHQEfgYUMC1wEqv5Y8inY0F/hTg3Ct8v9HyQH3fb7es15/BA53VApr57scBX/l0I2Ot6DqTsRZcZwqI9d2PAVb6xs+7wD2+/a8C/X33BwCv+u7fA7zj9WeIIp29CXQNcH7Ef5tuWaauAbZrrXdqrU8Cc4EUl977XCAFmOm7PxPo7KEsnqO1Xg78L9/uYDpKAWZph/8CVZVStdyRNHoIorNgpABztdYntNbfANtxfsPnFVrrfVrrdb77x4AsoA4y1oJSiM6Ccd6PNd94Oe57GOPbNPBb4H3f/vzjzIy/94F2SinlkrhRQSE6C0bEf5tuTabqAHv8HmdT+A/sfEYD/1RKrVVK9fXtS9Ba7wPnYgVc7Jl00UswHcnYK5yBPrP3DD/3segsHz5XSlOcFbCMtRDIpzOQsRYUpVRZpdQXwEFgEY6F7rDW+rTvFH+9WJ35jh8Bqrsrsffk15nW2oyzCb5x9helVHnfvoiPM7cmU4FmzZJGGJjWWutmwC3Aw0qpNl4LVMqRsRecV4Ak4GpgH/Ccb7/ozA+lVCyQCQzSWh8t7NQA+85LvQXQmYy1QtBa52itrwbq4ljmGgc6zXcrOqOgzpRSTYCRQCPgN8BFwHDf6RHXmVuTqWzgEr/HdYHvXHrvUoXW+jvf7UHgA5wf1gFjkvTdHvROwqglmI5k7AVBa33Ad0HKBaZxxr0iOvOhlIrBmRTM0VrP8+2WsVYIgXQmYy00tNaHgWU4cT1VlVKmf66/XqzOfMerELoL/5zDT2c3+9zMWmt9AngDF8eZW5Op1UCyLzvhApyguQ9deu9Sg1KqklIqztwHOgBf4ujqPt9p9wHzvZEwqgmmow+BXr5sjmuBI8ZFc76TL2bgDpyxBo7O7vFlDdUHkoFVbsvnNb44lOlAltZ6st8hGWtBCKYzGWvBUUrVUEpV9d2vALTHiTVbCnT1nZZ/nJnx1xX4VPuirM8Xguhsq98iR+HEmPmPs4j+Nsud/ZTw0VqfVkoNBBbiZPbN0FpvduO9SxkJwAe+WMJywNta60+UUquBd5VSDwK7gbs8lNFzlFJ/BW4C4pVS2cAYYCKBdfQPnEyO7cBPwP2uCxwFBNHZTb7UYY2TRdoPQGu9WSn1LrAFOA08rLXO8UJuj2kN9AQ2+WIzANKRsVYYwXTWTcZaUGoBM5VSZXEMHO9qrT9SSm0B5iqlxgPrcSap+G5nK6W241ik7vFCaI8JprNPlVI1cNx6XwAP+c6P+G9TKqBfYDKcAAAAXUlEQVQLgiAIgiCEgVRAFwRBEARBCAOZTAmCIAiCIISBTKYEQRAEQRDCQCZTgiAIgiAIYSCTKUEQBEEQhDCQyZQgCIIgCEIYyGRKEARBEAQhDGQyJQiCIAiCEAb/Dzc6/o9mwgPDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nextrow = next(row)\n",
    "print(\"Index:\", nextrow)\n",
    "print(\"Label:\", y_test.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "print(\"Guess:\", predicted.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "\n",
    "images = X_test.index_select(0,torch.tensor(nextrow))\n",
    "im = make_grid(images, nrow=r)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(np.transpose(im.numpy(), (1, 2, 0)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a new image through the model\n",
    "We can also pass a single image through the model to obtain a prediction.\n",
    "Pick a number from 0 to 9999, assign it to \"x\", and we'll use that value to select a number from the MNIST test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = 2019\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(test_data[x][0].reshape((28,28)), cmap=\"gist_yarg\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 9\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    new_pred = model(test_data[x][0].view(1,1,28,28)).argmax()\n",
    "print(\"Predicted value:\",new_pred.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
